services:

  # ════════════════════════════════════════
  # Infrastructure (Optimized/Alpine-like)
  # ════════════════════════════════════════

  kafka:
    image: docker.io/confluentinc/cp-kafka:7.6.1
    container_name: kafka
    ports:
      - "${KAFKA_PORT:-9092}:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    mem_limit: 1g
    cpus: 1.0


  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.1
    container_name: elasticsearch
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
    volumes:
      - es-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -sS -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    mem_limit: 1g
    cpus: 1.0

  ollama:
    image: docker.io/alpine/ollama:latest
    container_name: ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama-data:/root/.ollama
    healthcheck:
      test: ["CMD-SHELL", "netstat -an | grep :11434 | grep LISTEN || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    mem_limit: 6g
    cpus: 2.0

  mongodb:
    image: docker.io/mongo:7.0
    container_name: mongodb
    command: ["--replSet", "rs0", "--bind_ip_all"]
    ports:
      - "${MONGODB_PORT:-27017}:27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: ["CMD-SHELL", "mongosh --eval 'try { rs.initiate({_id: \"rs0\", members: [{_id: 0, host: \"mongodb:27017\"}]}); } catch (e) { }' && mongosh --eval 'db.adminCommand(\"ping\")'"]
      interval: 20s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.5

  redis:
    image: docker.io/redis:7.2-alpine
    container_name: redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    mem_limit: 256m
    cpus: 0.5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      AUTH_TYPE: DISABLED
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped
    mem_limit: 1g
    cpus: 0.5

  kafka-connect:
    build:
      context: .
      dockerfile: kafka-connect/Dockerfile
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    healthcheck:
      test: ["CMD", "curl", "-sS", "http://localhost:8083/connectors"]
      interval: 30s
      timeout: 10s
      retries: 5
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped
    mem_limit: 1.5g
    cpus: 0.5

  # ════════════════════════════════════════

  api-gateway:
    build:
      context: .
      dockerfile: api-gateway/Dockerfile
    container_name: api-gateway
    ports:
      - "${GATEWAY_PORT:-8080}:8080"
    environment:
      INGESTION_SERVICE_URL: http://ingestion-service:8085
      SEARCH_ORCHESTRATOR_URL: http://search-orchestrator:8081
    depends_on:
      ingestion-service:
        condition: service_healthy
    restart: unless-stopped
    mem_limit: 512m
    cpus: 0.5

  ingestion-service:
    build:
      context: .
      dockerfile: ingestion-service/Dockerfile
    container_name: ingestion-service
    ports:
      - "${INGESTION_PORT:-8085}:8085"
    environment:
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      SPRING_AI_OPENAI_BASE_URL: http://tei-sidecar:8080
      SPRING_AI_OPENAI_API_KEY: dummy_key_for_tei
      SPRING_AI_OPENAI_EMBEDDING_OPTIONS_MODEL: nomic-ai/nomic-embed-text-v1.5
      SPRING_DATA_MONGODB_URI: mongodb://mongodb:27017/ingestion-db
      SPRING_AI_VECTORSTORE_MONGODB_COLLECTION_NAME: documents
      SPRING_AI_VECTORSTORE_MONGODB_PATH_NAME: embedding
      SPRING_AI_VECTORSTORE_MONGODB_INDEX_NAME: vector_index
      SPRING_ELASTICSEARCH_URIS: http://elasticsearch:9200
      KAFKA_CONNECT_URL: http://kafka-connect:8083
    depends_on:
      tei-sidecar:
        condition: service_healthy
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy
    restart: unless-stopped
    mem_limit: 512g
    cpus: 0.5

  tei-sidecar:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
    container_name: tei-sidecar
    command: ["--model-id", "nomic-ai/nomic-embed-text-v1.5"]
    volumes:
      - tei-data:/data
    environment:
      - PORT=8080
    healthcheck:
      test: ["CMD-SHELL", "curl -sS -f http://localhost:8080/info || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 60s
    restart: unless-stopped
    mem_limit: 4g
    cpus: 2.0

volumes:
  es-data:
  ollama-data:
  tei-data:
  mongo-data:
  redis-data:
